{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPBFSiwRi3TbcKFIXqvvGCY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imon333/TensorFLow/blob/main/01_neural_network_regression_with_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction ro tegression with Neural Network in TensorFlow\n",
        "\n",
        "Predicting a numerical variable based on some other combination of variable , even shorter... predicting a number."
      ],
      "metadata": {
        "id": "d__pMK-gE-rK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Tensorflow\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17cIiy4zGesS",
        "outputId": "93313c2a-745f-46b3-a161-d730e50fa30e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Createing data to view and fit"
      ],
      "metadata": {
        "id": "IE_Z9KUpH6_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create features\n",
        "X = np.array([-7.0, -4.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n",
        "\n",
        "# create labels\n",
        "Y = np.array([3.0, 6.0, 9.0, 12.5, 14.0,21.0, 24.0])\n",
        "\n",
        "# Visualize it\n",
        "plt.scatter(X,Y);\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "dZkT5RW2HN4t",
        "outputId": "8db20394-4231-4ef8-a48c-d2e4680d7351"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Input and output shapes"
      ],
      "metadata": {
        "id": "Hvd-Ycg1JYFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a demo tensor for our housing price prediction problems\n",
        "\n",
        "house_info = tf.constant([\"bedroom\",\"bathroom\", \"garage\"])\n",
        "\n",
        "house_price = tf.constant([939500])\n",
        "\n",
        "house_info,house_price"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2KVWocSIAgC",
        "outputId": "65b5a647-8233-46ef-97c4-9f1551b960fb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,\n",
              " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939500], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[0] , Y[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qj69rmQmKfRY",
        "outputId": "6a52f7eb-e21d-4384-af25-dd154ce89da8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.float64(-7.0), np.float64(3.0))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = X[0].shape\n",
        "output_shape = Y[0].shape\n",
        "\n",
        "input_shape, output_shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TZ6hSNYJvHY",
        "outputId": "163725ae-5dc2-4274-860b-df0042bec4a5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((), ())"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn our NumPy arrays into tensors\n",
        "X = tf.constant(X)\n",
        "Y = tf.constant(Y)\n",
        "\n",
        "X,Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rG5xEMTzLDAB",
        "outputId": "3f6ccea3-f302-4c74-8fb2-f8146ff278ab"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(7,), dtype=float64, numpy=array([-7., -4.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(7,), dtype=float64, numpy=array([ 3. ,  6. ,  9. , 12.5, 14. , 21. , 24. ])>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = X[0].shape\n",
        "output_shape = Y[0].shape\n",
        "\n",
        "input_shape, output_shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DExdMx_MMLzi",
        "outputId": "977d257f-3fff-4d10-839f-eaf25b8841ef"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([]), TensorShape([]))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(X,Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "KhxD5gcpMVgL",
        "outputId": "0f0d43f9-657f-4936-936f-b503a9052740"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7b95a45cbdd0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Steps in modelling with tensorflow\n",
        "\n",
        "1. **Creating a model** - define the input and output layers, as well as the hidden layers of a deep learning model.\n",
        "2. **Compiling a model** - define the loss function (in others words, the function which tells our model how wrong it is) and the optimizer (tells our model how to improve the patterns its learning) and evaluation metrics (what we can use to interpret the performance of our model\n",
        ").\n",
        "3. **Fitting a model** - letting the model try to find patterns between X & Y (features and labels\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "lvzjfHXRMuPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# reshaping to 2D array so that it use Keras dimensional\n",
        "X = tf.reshape(X, (-1, 1))\n",
        "Y = tf.reshape(Y, (-1, 1))\n",
        "\n",
        "X,Y\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFyC6yQmY7Dm",
        "outputId": "d9728602-3017-4e2f-a96d-96f65448f10e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(7, 1), dtype=float64, numpy=\n",
              " array([[-7.],\n",
              "        [-4.],\n",
              "        [ 2.],\n",
              "        [ 5.],\n",
              "        [ 8.],\n",
              "        [11.],\n",
              "        [14.]])>,\n",
              " <tf.Tensor: shape=(7, 1), dtype=float64, numpy=\n",
              " array([[ 3. ],\n",
              "        [ 6. ],\n",
              "        [ 9. ],\n",
              "        [12.5],\n",
              "        [14. ],\n",
              "        [21. ],\n",
              "        [24. ]])>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "#1. Create a model using the Sequential API\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "#2. Compile the model\n",
        "model.compile(loss= tf.keras.losses.mae, # mae = short for mean absolute error\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "#3. Fit the model\n",
        "model.fit(X,Y, epochs=5)\n",
        "\n"
      ],
      "metadata": {
        "id": "bKw7hHp7Me3Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c5a3fc3-e123-4c75-e9d7-15da362cdb13"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 20.3426 - mae: 20.3426\n",
            "Epoch 2/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 19.9602 - mae: 19.9602\n",
            "Epoch 3/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 19.5777 - mae: 19.5777\n",
            "Epoch 4/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 19.1953 - mae: 19.1953\n",
            "Epoch 5/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 18.8128 - mae: 18.8128\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b95a456d0a0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chack out X And Y\n",
        "X,Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YX2EaM-XPd5",
        "outputId": "f4780c29-c12b-49fb-9f9d-6e57588a6a6b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(7, 1), dtype=float64, numpy=\n",
              " array([[-7.],\n",
              "        [-4.],\n",
              "        [ 2.],\n",
              "        [ 5.],\n",
              "        [ 8.],\n",
              "        [11.],\n",
              "        [14.]])>,\n",
              " <tf.Tensor: shape=(7, 1), dtype=float64, numpy=\n",
              " array([[ 3. ],\n",
              "        [ 6. ],\n",
              "        [ 9. ],\n",
              "        [12.5],\n",
              "        [14. ],\n",
              "        [21. ],\n",
              "        [24. ]])>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try and make a prediction using our model\n",
        "\n",
        "#issue: Keras predict() doesn't accept Python lists directly. You need to convert it to a TensorFlow tensor or NumPy array\n",
        "\n",
        "model.predict(tf.constant([[17.],[20]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Fq8c0jPa-2b",
        "outputId": "4e172576-57ca-449d-909c-bd9abe434ea3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-18.02821 ],\n",
              "       [-21.215961]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How we improve a model\n",
        "\n",
        "- we can improve our model, by altering the steps we took to create a model.\n",
        "\n",
        "1. **Create a model** - here we might add more layers, increase the model of hidden units (all called ceurons)\n",
        "within each of the hidden layers, change the activation function of each layer.\n",
        "\n",
        "2. **Compiling a model** - here we might change the optimization function or perhaps the **learning rate** of the optimization function.\n",
        "\n",
        "3. **Fitting a model** - here we might fit a model for more **epochs** (leave it training for longer) or on more data (give the model more examples to learn from)"
      ],
      "metadata": {
        "id": "mYvkeAk-dBPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's update the mdoel\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "               optimizer=tf.keras.optimizers.SGD(),\n",
        "               metrics=[\"mae\"]\n",
        "               )\n",
        "\n",
        "model.fit(X,Y, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Zyj8-VMbSWK",
        "outputId": "0cc94081-4564-4d73-bd43-1f85bf98c4a2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 532ms/step - loss: 9.8356 - mae: 9.8356\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 9.6540 - mae: 9.6540\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 9.4724 - mae: 9.4724\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 9.2907 - mae: 9.2907\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 9.1091 - mae: 9.1091\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 8.9275 - mae: 8.9275\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 8.7458 - mae: 8.7458\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 8.5642 - mae: 8.5642\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 8.3826 - mae: 8.3826\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 8.2009 - mae: 8.2009\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 8.0193 - mae: 8.0193\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 7.8377 - mae: 7.8377\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 7.6560 - mae: 7.6560\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 7.4744 - mae: 7.4744\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 7.2928 - mae: 7.2928\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 7.1111 - mae: 7.1111\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 6.9295 - mae: 6.9295\n",
            "Epoch 18/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 6.7479 - mae: 6.7479\n",
            "Epoch 19/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 6.5662 - mae: 6.5662\n",
            "Epoch 20/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 6.3846 - mae: 6.3846\n",
            "Epoch 21/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 6.2030 - mae: 6.2030\n",
            "Epoch 22/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 6.0213 - mae: 6.0213\n",
            "Epoch 23/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 5.8397 - mae: 5.8397\n",
            "Epoch 24/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 5.6581 - mae: 5.6581\n",
            "Epoch 25/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 5.5134 - mae: 5.5134\n",
            "Epoch 26/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 5.5081 - mae: 5.5081\n",
            "Epoch 27/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 5.5028 - mae: 5.5028\n",
            "Epoch 28/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 5.4975 - mae: 5.4975\n",
            "Epoch 29/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 5.4921 - mae: 5.4921\n",
            "Epoch 30/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 5.4868 - mae: 5.4868\n",
            "Epoch 31/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 5.4822 - mae: 5.4822\n",
            "Epoch 32/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 5.4826 - mae: 5.4826\n",
            "Epoch 33/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 5.5190 - mae: 5.5190\n",
            "Epoch 34/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 5.4712 - mae: 5.4712\n",
            "Epoch 35/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 5.4699 - mae: 5.4699\n",
            "Epoch 36/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 5.5080 - mae: 5.5080\n",
            "Epoch 37/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 5.4602 - mae: 5.4602\n",
            "Epoch 38/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 5.4573 - mae: 5.4573\n",
            "Epoch 39/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 5.4969 - mae: 5.4969\n",
            "Epoch 40/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 5.4492 - mae: 5.4492\n",
            "Epoch 41/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 5.4446 - mae: 5.4446\n",
            "Epoch 42/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 5.4859 - mae: 5.4859\n",
            "Epoch 43/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 5.4382 - mae: 5.4382\n",
            "Epoch 44/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 5.4319 - mae: 5.4319\n",
            "Epoch 45/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 5.4749 - mae: 5.4749\n",
            "Epoch 46/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 5.4271 - mae: 5.4271\n",
            "Epoch 47/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 5.4193 - mae: 5.4193\n",
            "Epoch 48/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 5.4639 - mae: 5.4639\n",
            "Epoch 49/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 5.4161 - mae: 5.4161\n",
            "Epoch 50/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 5.4066 - mae: 5.4066\n",
            "Epoch 51/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 5.4529 - mae: 5.4529\n",
            "Epoch 52/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 5.4051 - mae: 5.4051\n",
            "Epoch 53/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 5.3940 - mae: 5.3940\n",
            "Epoch 54/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 5.4418 - mae: 5.4418\n",
            "Epoch 55/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 5.3941 - mae: 5.3941\n",
            "Epoch 56/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 5.3813 - mae: 5.3813\n",
            "Epoch 57/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 5.4308 - mae: 5.4308\n",
            "Epoch 58/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 5.3831 - mae: 5.3831\n",
            "Epoch 59/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 5.3687 - mae: 5.3687\n",
            "Epoch 60/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 5.4198 - mae: 5.4198\n",
            "Epoch 61/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 5.3720 - mae: 5.3720\n",
            "Epoch 62/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 5.3560 - mae: 5.3560\n",
            "Epoch 63/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 5.4088 - mae: 5.4088\n",
            "Epoch 64/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 5.3610 - mae: 5.3610\n",
            "Epoch 65/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 5.3434 - mae: 5.3434\n",
            "Epoch 66/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 5.3977 - mae: 5.3977\n",
            "Epoch 67/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 5.3500 - mae: 5.3500\n",
            "Epoch 68/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 5.3307 - mae: 5.3307\n",
            "Epoch 69/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 5.3867 - mae: 5.3867\n",
            "Epoch 70/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 5.3390 - mae: 5.3390\n",
            "Epoch 71/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 5.3181 - mae: 5.3181\n",
            "Epoch 72/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 5.3757 - mae: 5.3757\n",
            "Epoch 73/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 5.3280 - mae: 5.3280\n",
            "Epoch 74/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 5.3054 - mae: 5.3054\n",
            "Epoch 75/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 5.3647 - mae: 5.3647\n",
            "Epoch 76/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 5.3169 - mae: 5.3169\n",
            "Epoch 77/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 5.2928 - mae: 5.2928\n",
            "Epoch 78/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 5.3537 - mae: 5.3537\n",
            "Epoch 79/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 5.3059 - mae: 5.3059\n",
            "Epoch 80/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 5.2801 - mae: 5.2801\n",
            "Epoch 81/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 5.3426 - mae: 5.3426\n",
            "Epoch 82/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 5.2949 - mae: 5.2949\n",
            "Epoch 83/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 5.2675 - mae: 5.2675\n",
            "Epoch 84/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 5.3316 - mae: 5.3316\n",
            "Epoch 85/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 5.2839 - mae: 5.2839\n",
            "Epoch 86/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 5.2548 - mae: 5.2548\n",
            "Epoch 87/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 5.3206 - mae: 5.3206\n",
            "Epoch 88/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 5.2728 - mae: 5.2728\n",
            "Epoch 89/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 5.2422 - mae: 5.2422\n",
            "Epoch 90/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 5.3096 - mae: 5.3096\n",
            "Epoch 91/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 5.2618 - mae: 5.2618\n",
            "Epoch 92/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 5.2295 - mae: 5.2295\n",
            "Epoch 93/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 5.2986 - mae: 5.2986\n",
            "Epoch 94/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 5.2508 - mae: 5.2508\n",
            "Epoch 95/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 5.2168 - mae: 5.2168\n",
            "Epoch 96/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 5.2875 - mae: 5.2875\n",
            "Epoch 97/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 5.2398 - mae: 5.2398\n",
            "Epoch 98/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 5.2042 - mae: 5.2042\n",
            "Epoch 99/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 5.2765 - mae: 5.2765\n",
            "Epoch 100/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 5.2288 - mae: 5.2288\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b95a2101580>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "X,Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mqd21qFdjkkc",
        "outputId": "ffd54325-b9a9-4546-927d-b484fbd6cc78"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(7, 1), dtype=float64, numpy=\n",
              " array([[-7.],\n",
              "        [-4.],\n",
              "        [ 2.],\n",
              "        [ 5.],\n",
              "        [ 8.],\n",
              "        [11.],\n",
              "        [14.]])>,\n",
              " <tf.Tensor: shape=(7, 1), dtype=float64, numpy=\n",
              " array([[ 3. ],\n",
              "        [ 6. ],\n",
              "        [ 9. ],\n",
              "        [12.5],\n",
              "        [14. ],\n",
              "        [21. ],\n",
              "        [24. ]])>)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predictstion\n",
        "model.predict(tf.constant([[17.],[20.]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILNZJL4ajmKu",
        "outputId": "af395e88-125a-4b9b-b5e6-2bc33169b0c8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[28.945557],\n",
              "       [33.927547]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Let's see if we can make another to improve our model"
      ],
      "metadata": {
        "id": "8-6tgRseuHSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. create the model (this time with an extra hidden layer with 100 hidden units)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(50, activation= None),\n",
        "    tf.keras.layers.Dense(1)\n",
        "                             ])\n",
        "# 2. Compile the model\n",
        "model.compile(loss= \"mae\",\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "model.fit(X,Y, epochs=100)\n",
        "\n"
      ],
      "metadata": {
        "id": "niJ8febRjqhz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45d75825-c03c-4532-f96f-6ef9ab1bfa58"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 14.3539 - mae: 14.3539\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 13.4859 - mae: 13.4859\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 12.6185 - mae: 12.6185\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 11.7508 - mae: 11.7508\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 10.8811 - mae: 10.8811\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 10.0074 - mae: 10.0074\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 9.1277 - mae: 9.1277\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 8.2399 - mae: 8.2399\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 7.3416 - mae: 7.3416\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 6.4306 - mae: 6.4306\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 5.5045 - mae: 5.5045\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 5.0813 - mae: 5.0813\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 5.6112 - mae: 5.6112\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 6.1020 - mae: 6.1020\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 6.3196 - mae: 6.3196\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 6.3231 - mae: 6.3231\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 6.1580 - mae: 6.1580\n",
            "Epoch 18/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 5.8603 - mae: 5.8603\n",
            "Epoch 19/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 5.4582 - mae: 5.4582\n",
            "Epoch 20/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 4.9744 - mae: 4.9744\n",
            "Epoch 21/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 4.7025 - mae: 4.7025\n",
            "Epoch 22/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 4.5740 - mae: 4.5740\n",
            "Epoch 23/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 4.7736 - mae: 4.7736\n",
            "Epoch 24/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 4.9266 - mae: 4.9266\n",
            "Epoch 25/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 4.9661 - mae: 4.9661\n",
            "Epoch 26/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 4.9064 - mae: 4.9064\n",
            "Epoch 27/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 4.7588 - mae: 4.7588\n",
            "Epoch 28/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 4.5320 - mae: 4.5320\n",
            "Epoch 29/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 4.3039 - mae: 4.3039\n",
            "Epoch 30/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 4.1276 - mae: 4.1276\n",
            "Epoch 31/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 4.1654 - mae: 4.1654\n",
            "Epoch 32/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 4.2002 - mae: 4.2002\n",
            "Epoch 33/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 4.2182 - mae: 4.2182\n",
            "Epoch 34/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 4.2085 - mae: 4.2085\n",
            "Epoch 35/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 4.0810 - mae: 4.0810\n",
            "Epoch 36/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 3.9800 - mae: 3.9800\n",
            "Epoch 37/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 3.8660 - mae: 3.8660\n",
            "Epoch 38/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 3.7400 - mae: 3.7400\n",
            "Epoch 39/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 3.6029 - mae: 3.6029\n",
            "Epoch 40/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 3.6302 - mae: 3.6302\n",
            "Epoch 41/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 3.6336 - mae: 3.6336\n",
            "Epoch 42/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 3.6057 - mae: 3.6057\n",
            "Epoch 43/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 3.5488 - mae: 3.5488\n",
            "Epoch 44/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 3.4647 - mae: 3.4647\n",
            "Epoch 45/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 3.3547 - mae: 3.3547\n",
            "Epoch 46/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 3.2202 - mae: 3.2202\n",
            "Epoch 47/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 3.0620 - mae: 3.0620\n",
            "Epoch 48/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 3.0265 - mae: 3.0265\n",
            "Epoch 49/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 3.0027 - mae: 3.0027\n",
            "Epoch 50/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 2.9527 - mae: 2.9527\n",
            "Epoch 51/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.8779 - mae: 2.8779\n",
            "Epoch 52/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 2.7795 - mae: 2.7795\n",
            "Epoch 53/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 2.6588 - mae: 2.6588\n",
            "Epoch 54/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 2.5167 - mae: 2.5167\n",
            "Epoch 55/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 2.3542 - mae: 2.3542\n",
            "Epoch 56/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 2.2838 - mae: 2.2838\n",
            "Epoch 57/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 2.2329 - mae: 2.2329\n",
            "Epoch 58/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 2.1404 - mae: 2.1404\n",
            "Epoch 59/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 2.0084 - mae: 2.0084\n",
            "Epoch 60/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.8785 - mae: 1.8785\n",
            "Epoch 61/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.8476 - mae: 1.8476\n",
            "Epoch 62/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.8941 - mae: 1.8941\n",
            "Epoch 63/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.8241 - mae: 1.8241\n",
            "Epoch 64/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 1.7602 - mae: 1.7602\n",
            "Epoch 65/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.7321 - mae: 1.7321\n",
            "Epoch 66/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.7050 - mae: 1.7050\n",
            "Epoch 67/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 1.6788 - mae: 1.6788\n",
            "Epoch 68/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.6534 - mae: 1.6534\n",
            "Epoch 69/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.6288 - mae: 1.6288\n",
            "Epoch 70/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 1.6048 - mae: 1.6048\n",
            "Epoch 71/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 1.5813 - mae: 1.5813\n",
            "Epoch 72/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 1.5583 - mae: 1.5583\n",
            "Epoch 73/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.5357 - mae: 1.5357\n",
            "Epoch 74/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.5966 - mae: 1.5966\n",
            "Epoch 75/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.6303 - mae: 1.6303\n",
            "Epoch 76/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.6256 - mae: 1.6256\n",
            "Epoch 77/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 1.5861 - mae: 1.5861\n",
            "Epoch 78/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 1.5152 - mae: 1.5152\n",
            "Epoch 79/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.4836 - mae: 1.4836\n",
            "Epoch 80/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.4848 - mae: 1.4848\n",
            "Epoch 81/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.4842 - mae: 1.4842\n",
            "Epoch 82/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.4819 - mae: 1.4819\n",
            "Epoch 83/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.4781 - mae: 1.4781\n",
            "Epoch 84/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 1.6543 - mae: 1.6543\n",
            "Epoch 85/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.4641 - mae: 1.4641\n",
            "Epoch 86/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.4544 - mae: 1.4544\n",
            "Epoch 87/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.4439 - mae: 1.4439\n",
            "Epoch 88/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 1.4325 - mae: 1.4325\n",
            "Epoch 89/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 1.4847 - mae: 1.4847\n",
            "Epoch 90/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 1.5141 - mae: 1.5141\n",
            "Epoch 91/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 1.5055 - mae: 1.5055\n",
            "Epoch 92/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 1.4627 - mae: 1.4627\n",
            "Epoch 93/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.4200 - mae: 1.4200\n",
            "Epoch 94/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 1.4237 - mae: 1.4237\n",
            "Epoch 95/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 1.4252 - mae: 1.4252\n",
            "Epoch 96/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 1.4336 - mae: 1.4336\n",
            "Epoch 97/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.4207 - mae: 1.4207\n",
            "Epoch 98/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.4153 - mae: 1.4153\n",
            "Epoch 99/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.4084 - mae: 1.4084\n",
            "Epoch 100/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 1.4002 - mae: 1.4002\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b94f729a0c0>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# X,Y"
      ],
      "metadata": {
        "id": "smZjsQQ8zE_P"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predictstion of improved model\n",
        "\n",
        "model.predict(tf.constant([[17.0]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef4IdICUyz54",
        "outputId": "7d29c8f3-3de7-46d4-affc-79069ede8840"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[25.846172]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluting a model\n",
        "\n",
        "In practice , a typical workflow you'll go through when building neural networks is :\n",
        "\n",
        "Building a model -> fit it -> evaluate it -> tweak a model -> fit it -> evaluate it -> tweak a model -> fit it -> evaluate it -> ....\n"
      ],
      "metadata": {
        "id": "H4V-jWBr12nE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When it comes to evaluation... there are 3 words you should memorize:\n",
        "> \"Visualize, visualize, visualize\"\n",
        "\n",
        "* The data - what data are we working with ? what does it look like ?\n",
        "* The model itself - what does our model look like ?\n",
        "* The trianing of a model - how does a model perform while it learns?\n",
        "* The predictions of the model - how do the predictions of a model line up against the ground truth (the original labels)?"
      ],
      "metadata": {
        "id": "JqoPe4_L3qfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a bigger dataset\n",
        "X2 = tf.range(-100,100,5)\n",
        "\n",
        "X2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJ6UGLIVzCKK",
        "outputId": "b2c75f9e-dd94-4a39-c02e-19f3604c097c"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(40,), dtype=int32, numpy=\n",
              "array([-100,  -95,  -90,  -85,  -80,  -75,  -70,  -65,  -60,  -55,  -50,\n",
              "        -45,  -40,  -35,  -30,  -25,  -20,  -15,  -10,   -5,    0,    5,\n",
              "         10,   15,   20,   25,   30,   35,   40,   45,   50,   55,   60,\n",
              "         65,   70,   75,   80,   85,   90,   95], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y2 = X2 +10\n",
        "Y2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVYP08jC5qou",
        "outputId": "78e31e57-3a2a-417f-f523-5ff82a692b5f"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(40,), dtype=int32, numpy=\n",
              "array([-90, -85, -80, -75, -70, -65, -60, -55, -50, -45, -40, -35, -30,\n",
              "       -25, -20, -15, -10,  -5,   0,   5,  10,  15,  20,  25,  30,  35,\n",
              "        40,  45,  50,  55,  60,  65,  70,  75,  80,  85,  90,  95, 100,\n",
              "       105], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reshaping to 2D array so that it use Keras dimensional\n",
        "X2 = tf.reshape(X2, (-1, 1))\n",
        "Y2 = tf.reshape(Y2, (-1, 1))\n"
      ],
      "metadata": {
        "id": "v-IVqoPC5-LB"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's update the mdoel\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "               optimizer=tf.keras.optimizers.SGD(),\n",
        "               metrics=[\"mae\"]\n",
        "               )\n",
        "\n",
        "model.fit(X2,Y2, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SkEBJhs5V3B",
        "outputId": "5c495d93-bdb8-4a69-e856-4ee2d62eff31"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 175ms/step - loss: 28.2907 - mae: 28.2907\n",
            "Epoch 2/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 10.2431 - mae: 10.2431\n",
            "Epoch 3/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 9.9577 - mae: 9.9577\n",
            "Epoch 4/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.8127 - mae: 9.8127\n",
            "Epoch 5/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 9.7597 - mae: 9.7597\n",
            "Epoch 6/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 10.1502 - mae: 10.1502\n",
            "Epoch 7/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 10.0052 - mae: 10.0052\n",
            "Epoch 8/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.8602 - mae: 9.8602\n",
            "Epoch 9/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9.7152 - mae: 9.7152\n",
            "Epoch 10/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9.6654 - mae: 9.6654\n",
            "Epoch 11/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 10.0527 - mae: 10.0527\n",
            "Epoch 12/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.9077 - mae: 9.9077\n",
            "Epoch 13/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9.7627 - mae: 9.7627\n",
            "Epoch 14/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9.6177 - mae: 9.6177\n",
            "Epoch 15/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.5712 - mae: 9.5712\n",
            "Epoch 16/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.9552 - mae: 9.9552\n",
            "Epoch 17/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.8102 - mae: 9.8102\n",
            "Epoch 18/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.6652 - mae: 9.6652\n",
            "Epoch 19/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.5202 - mae: 9.5202\n",
            "Epoch 20/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.3968 - mae: 9.3968\n",
            "Epoch 21/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.4504 - mae: 9.4504\n",
            "Epoch 22/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9.8610 - mae: 9.8610\n",
            "Epoch 23/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.4289 - mae: 9.4289\n",
            "Epoch 24/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9.3694 - mae: 9.3694\n",
            "Epoch 25/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.4293 - mae: 9.4293\n",
            "Epoch 26/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.3585 - mae: 9.3585\n",
            "Epoch 27/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9.7763 - mae: 9.7763\n",
            "Epoch 28/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 9.3339 - mae: 9.3339\n",
            "Epoch 29/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.2847 - mae: 9.2847\n",
            "Epoch 30/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.3343 - mae: 9.3343\n",
            "Epoch 31/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9.2667 - mae: 9.2667\n",
            "Epoch 32/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.6916 - mae: 9.6916\n",
            "Epoch 33/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.2389 - mae: 9.2389\n",
            "Epoch 34/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9.2000 - mae: 9.2000\n",
            "Epoch 35/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9.2393 - mae: 9.2393\n",
            "Epoch 36/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.1749 - mae: 9.1749\n",
            "Epoch 37/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.6069 - mae: 9.6069\n",
            "Epoch 38/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9.1439 - mae: 9.1439\n",
            "Epoch 39/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9.1153 - mae: 9.1153\n",
            "Epoch 40/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.1443 - mae: 9.1443\n",
            "Epoch 41/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 9.0830 - mae: 9.0830\n",
            "Epoch 42/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9.5222 - mae: 9.5222\n",
            "Epoch 43/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.0489 - mae: 9.0489\n",
            "Epoch 44/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.0484 - mae: 9.0484\n",
            "Epoch 45/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.1827 - mae: 9.1827\n",
            "Epoch 46/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.0377 - mae: 9.0377\n",
            "Epoch 47/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8.9699 - mae: 8.9699\n",
            "Epoch 48/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9.4580 - mae: 9.4580\n",
            "Epoch 49/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 8.9699 - mae: 8.9699\n",
            "Epoch 50/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9.0889 - mae: 9.0889\n",
            "Epoch 51/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 8.9439 - mae: 8.9439\n",
            "Epoch 52/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 8.8792 - mae: 8.8792\n",
            "Epoch 53/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.3795 - mae: 9.3795\n",
            "Epoch 54/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 8.8914 - mae: 8.8914\n",
            "Epoch 55/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8.9952 - mae: 8.9952\n",
            "Epoch 56/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8.8502 - mae: 8.8502\n",
            "Epoch 57/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 8.7886 - mae: 8.7886\n",
            "Epoch 58/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9.3010 - mae: 9.3010\n",
            "Epoch 59/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 8.8129 - mae: 8.8129\n",
            "Epoch 60/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8.9014 - mae: 8.9014\n",
            "Epoch 61/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8.7564 - mae: 8.7564\n",
            "Epoch 62/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8.6980 - mae: 8.6980\n",
            "Epoch 63/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.3570 - mae: 9.3570\n",
            "Epoch 64/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.0321 - mae: 9.0321\n",
            "Epoch 65/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 8.8871 - mae: 8.8871\n",
            "Epoch 66/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8.7421 - mae: 8.7421\n",
            "Epoch 67/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 8.5971 - mae: 8.5971\n",
            "Epoch 68/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8.6700 - mae: 8.6700\n",
            "Epoch 69/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8.7308 - mae: 8.7308\n",
            "Epoch 70/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8.5858 - mae: 8.5858\n",
            "Epoch 71/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8.5330 - mae: 8.5330\n",
            "Epoch 72/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.2290 - mae: 9.2290\n",
            "Epoch 73/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 8.8468 - mae: 8.8468\n",
            "Epoch 74/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 8.5686 - mae: 8.5686\n",
            "Epoch 75/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 8.4453 - mae: 8.4453\n",
            "Epoch 76/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 9.9879 - mae: 9.9879\n",
            "Epoch 77/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 10.9764 - mae: 10.9764\n",
            "Epoch 78/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 10.8010 - mae: 10.8010\n",
            "Epoch 79/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 10.6306 - mae: 10.6306\n",
            "Epoch 80/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 14.1052 - mae: 14.1052\n",
            "Epoch 81/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 13.5526 - mae: 13.5526\n",
            "Epoch 82/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 13.8634 - mae: 13.8634\n",
            "Epoch 83/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 10.6157 - mae: 10.6157\n",
            "Epoch 84/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 14.0964 - mae: 14.0964\n",
            "Epoch 85/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 13.5423 - mae: 13.5423\n",
            "Epoch 86/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 13.8522 - mae: 13.8522\n",
            "Epoch 87/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 10.6007 - mae: 10.6007\n",
            "Epoch 88/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 14.0877 - mae: 14.0877\n",
            "Epoch 89/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 13.5320 - mae: 13.5320\n",
            "Epoch 90/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 13.8409 - mae: 13.8409\n",
            "Epoch 91/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 10.5857 - mae: 10.5857\n",
            "Epoch 92/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 14.0789 - mae: 14.0789\n",
            "Epoch 93/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 13.5217 - mae: 13.5217\n",
            "Epoch 94/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 13.9660 - mae: 13.9660\n",
            "Epoch 95/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 13.4140 - mae: 13.4140\n",
            "Epoch 96/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 13.7221 - mae: 13.7221\n",
            "Epoch 97/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 14.1792 - mae: 14.1792\n",
            "Epoch 98/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 13.6144 - mae: 13.6144\n",
            "Epoch 99/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 14.0662 - mae: 14.0662\n",
            "Epoch 100/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 13.5067 - mae: 13.5067\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b94f4525a60>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zfrw3eic58e5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}